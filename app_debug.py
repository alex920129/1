
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
from pathlib import Path

st.set_page_config(page_title="å¿ƒè„ç—…é¢„æµ‹ Â· Debug ç‰ˆ", page_icon="ğŸ› ï¸", layout="centered")
st.title("ğŸ› ï¸ å¿ƒè„ç—…é¢„æµ‹ï¼ˆDebug ç‰ˆï¼‰")

st.markdown("""
è¿™ä¸ªé¡µé¢ä¼š **è‡ªåŠ¨åœ¨å¤šå¤„è·¯å¾„å¯»æ‰¾æ¨¡å‹**ï¼Œå¹¶å±•ç¤º**å½“å‰å·¥ä½œç›®å½•ä¸æ–‡ä»¶åˆ—è¡¨**ï¼Œå¸®åŠ©å®šä½â€œæœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹â€çš„åŸå› ã€‚
""")

# ---------- æ˜¾ç¤ºè¿è¡Œç¯å¢ƒä¿¡æ¯ ----------
cwd = Path.cwd()
here = Path(__file__).resolve().parent
st.write("**å½“å‰å·¥ä½œç›®å½• (Path.cwd())**ï¼š", str(cwd))
st.write("**app æ–‡ä»¶æ‰€åœ¨ç›®å½• (__file__)**ï¼š", str(here))

def list_dir(p: Path, depth=1):
    rows = []
    try:
        for item in p.iterdir():
            rows.append({"name": item.name, "is_dir": item.is_dir(), "size": (item.stat().st_size if item.is_file() else None)})
    except Exception as e:
        rows.append({"name": f"<æ— æ³•åˆ—å‡º: {e}>", "is_dir": "", "size": ""})
    return rows

with st.expander("æŸ¥çœ‹å½“å‰ç›®å½•æ–‡ä»¶åˆ—è¡¨", expanded=False):
    import pandas as pd
    st.dataframe(pd.DataFrame(list_dir(cwd)))

with st.expander("æŸ¥çœ‹ app.py æ‰€åœ¨ç›®å½•æ–‡ä»¶åˆ—è¡¨", expanded=False):
    import pandas as pd
    st.dataframe(pd.DataFrame(list_dir(here)))

# ---------- å¯»æ‰¾æ¨¡å‹/CSV ----------
candidate_dirs = [
    cwd,
    here,
    cwd / "model",
    cwd / "models",
    cwd / "data",
    cwd / "assets",
]

env_model = os.getenv("MODEL_PATH")
env_csv = os.getenv("CSV_PATH")

model_candidates = []
csv_candidates = []

if env_model:
    model_candidates.append(Path(env_model))
for d in candidate_dirs:
    model_candidates.append(d / "best_model.pkl")

if env_csv:
    csv_candidates.append(Path(env_csv))
for d in candidate_dirs:
    csv_candidates.append(d / "heart_disease_uci .csv")  # ä¿æŒåŸæ–‡ä»¶åï¼ˆå«ç©ºæ ¼ï¼‰

def first_existing(paths):
    for p in paths:
        if p.exists():
            return p
    return None

MODEL_PATH = first_existing(model_candidates)
CSV_PATH = first_existing(csv_candidates)

st.write("**æ¨¡å‹å€™é€‰è·¯å¾„ï¼ˆæŒ‰é¡ºåºï¼‰**ï¼š", [str(p) for p in model_candidates[:6]] + (["..."] if len(model_candidates) > 6 else []))
st.write("**æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„**ï¼š", str(MODEL_PATH) if MODEL_PATH else ":x: æ²¡æ‰¾åˆ°")

st.write("**CSV å€™é€‰è·¯å¾„ï¼ˆæŒ‰é¡ºåºï¼‰**ï¼š", [str(p) for p in csv_candidates[:6]] + (["..."] if len(csv_candidates) > 6 else []))
st.write("**æ‰¾åˆ°çš„ CSV è·¯å¾„**ï¼š", str(CSV_PATH) if CSV_PATH else ":warning: æ²¡æ‰¾åˆ°ï¼ˆéè‡´å‘½ï¼‰")

def is_git_lfs_pointer(path: Path):
    try:
        if path.is_file() and path.stat().st_size < 1024:
            head = path.read_text(errors="ignore")[:200]
            return "git-lfs.github.com/spec" in head
    except Exception:
        pass
    return False

if MODEL_PATH:
    if is_git_lfs_pointer(MODEL_PATH):
        st.error("æ£€æµ‹åˆ° **Git LFS æŒ‡é’ˆæ–‡ä»¶**ï¼Œè€ŒéçœŸå®æ¨¡å‹ã€‚è¯·åœ¨ä»“åº“å¯ç”¨ Git LFSï¼Œå¹¶ç¡®ä¿éƒ¨ç½²æ—¶ LFS å¯¹è±¡è¢«æ­£ç¡®æ‹‰å–ã€‚")
        st.stop()

# ---------- å…è®¸æ‰‹åŠ¨ä¸Šä¼ å…œåº• ----------
st.sidebar.header("ğŸ“‚ å…œåº•ä¸Šä¼ ")
model_file = None
if MODEL_PATH is None:
    model_file = st.sidebar.file_uploader("ä¸Šä¼ æ¨¡å‹ï¼ˆ.pklï¼‰", type=["pkl"])
csv_file = None
if CSV_PATH is None:
    csv_file = st.sidebar.file_uploader("ä¸Šä¼ ç¤ºä¾‹ CSV", type=["csv"])

# ---------- åŠ è½½æ¨¡å‹/CSV ----------
def load_model(file_like, path: Path):
    try:
        if file_like is not None:
            return pickle.load(file_like)
        elif path is not None and path.exists():
            with path.open("rb") as f:
                return pickle.load(f)
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        st.stop()
    return None

def load_csv(file_like, path: Path):
    try:
        if file_like is not None:
            return pd.read_csv(file_like)
        elif path is not None and path.exists():
            return pd.read_csv(path)
    except Exception as e:
        st.warning(f"CSV è¯»å–å¤±è´¥ï¼š{e}")
        return None
    return None

model = load_model(model_file, MODEL_PATH)
df = load_csv(csv_file, CSV_PATH)

if model is None:
    st.error("ä»ç„¶æ²¡æœ‰åŠ è½½åˆ°æ¨¡å‹ã€‚è¯·ç¡®è®¤æ–‡ä»¶åä¸è·¯å¾„ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦ä¸º Git LFS æŒ‡é’ˆã€‚")
    st.stop()

# ---------- æ¨æ–­ç‰¹å¾åå¹¶ç”Ÿæˆè¡¨å• ----------
if hasattr(model, "feature_names_in_"):
    feature_names = list(model.feature_names_in_)
elif df is not None:
    feature_names = list(df.columns)
else:
    st.error("æ— æ³•ç¡®å®šç‰¹å¾åã€‚è¯·æä¾› CSV æˆ–ä½¿ç”¨å¸¦ feature_names_in_ çš„æ¨¡å‹ï¼ˆPipeline æœ€ä½³ï¼‰ã€‚")
    st.stop()

st.sidebar.header("ğŸ§® å¡«å†™ç‰¹å¾å€¼")

def build_default(series: pd.Series):
    if series is None or series.empty:
        return ""
    if pd.api.types.is_numeric_dtype(series):
        return float(series.median())
    try:
        return series.mode().iloc[0]
    except Exception:
        return ""

def widget_for_column(col: str):
    col_series = df[col] if (df is not None and col in df.columns) else None
    is_numeric = pd.api.types.is_numeric_dtype(col_series) if col_series is not None else True
    if is_numeric:
        if col_series is not None and not col_series.empty:
            q01 = float(col_series.quantile(0.01))
            q99 = float(col_series.quantile(0.99))
            default_val = build_default(col_series)
            non_na = col_series.dropna()
            is_int_like = len(non_na) > 0 and all(float(x).is_integer() for x in non_na[: min(200, len(non_na))])
            step = 1.0 if is_int_like else 0.1
        else:
            q01, q99, default_val, step = 0.0, 100.0, 0.0, 1.0
        return st.sidebar.number_input(f"{col}", min_value=q01, max_value=q99, value=float(default_val), step=step, key=f"num_{col}")
    else:
        uniques = col_series.dropna().unique().tolist() if (col_series is not None and not col_series.empty) else []
        if 0 < len(uniques) <= 15:
            default_val = build_default(col_series) if col_series is not None else (uniques[0] if uniques else "")
            idx = uniques.index(default_val) if default_val in uniques else 0
            return st.sidebar.selectbox(f"{col}", options=uniques or [""], index=idx, key=f"cat_{col}")
        else:
            default_val = build_default(col_series) if col_series is not None else ""
            return st.sidebar.text_input(f"{col}", value=str(default_val), key=f"text_{col}")

user_input = {col: widget_for_column(col) for col in feature_names}
X = pd.DataFrame([user_input], columns=feature_names)

st.markdown("### ä½ çš„è¾“å…¥")
st.dataframe(X, use_container_width=True)

if st.sidebar.button("é¢„æµ‹", type="primary", use_container_width=True):
    try:
        y_pred = model.predict(X)
        st.markdown("### é¢„æµ‹ç»“æœ")
        st.success(f"é¢„æµ‹ç±»åˆ«ï¼š**{y_pred[0]}**")
        if hasattr(model, "predict_proba"):
            try:
                proba = model.predict_proba(X)
                if proba.shape[1] == 2:
                    st.info(f"é˜³æ€§æ¦‚ç‡ï¼š**{proba[0,1]:.3f}**ï¼›é˜´æ€§æ¦‚ç‡ï¼š{proba[0,0]:.3f}")
                else:
                    import pandas as pd
                    prob_series = pd.Series(proba[0], index=getattr(model, "classes_", list(range(proba.shape[1]))))
                    st.dataframe(prob_series.to_frame("probability"))
            except Exception:
                pass
    except Exception as e:
        st.error(f"é¢„æµ‹å¤±è´¥ï¼š{e}")
        st.caption("å¤šä¸ºåˆ—å/ç±»å‹ä¸ä¸€è‡´æˆ–ç¼ºå°‘é¢„å¤„ç†ã€‚å»ºè®®å°†é¢„å¤„ç†ä¸æ¨¡å‹å°è£…åˆ° sklearn Pipeline åå†ä¿å­˜ã€‚")
