
import streamlit as st
import pandas as pd
import joblib
from pathlib import Path

st.set_page_config(page_title="å¿ƒè„ç—…é¢„æµ‹ Â· Streamlit", page_icon="â¤ï¸", layout="centered")

st.title("â¤ï¸ å¿ƒè„ç—…é¢„æµ‹ï¼ˆStreamlit ç‰ˆï¼‰")
st.caption("å»ºè®®ï¼šç»Ÿä¸€ä½¿ç”¨åˆ—å **thalch**ï¼ˆæœ€å¤§å¿ƒçŽ‡ï¼‰ã€‚æœ¬åº”ç”¨ä¼˜å…ˆåŠ è½½ä»“åº“æ ¹ç›®å½•ä¸‹çš„æ¨¡åž‹æ–‡ä»¶ã€‚")

# ---------- 1) é€‰æ‹©ä¸ŽåŠ è½½æ¨¡åž‹ï¼ˆä¼˜å…ˆ best_model_pipe.pklï¼Œå›žé€€ best_model.pklï¼›å¦åˆ™å…è®¸ä¸Šä¼ ï¼‰ ----------
BASE_DIR = Path(__file__).resolve().parent
CANDIDATES = [BASE_DIR / "best_model_pipe.pkl", BASE_DIR / "best_model.pkl"]

st.subheader("â‘  åŠ è½½æ¨¡åž‹")
loaded = None
loaded_path = None
for p in CANDIDATES:
    if p.exists():
        loaded = joblib.load(p)
        loaded_path = p
        break

upload_file = None
if loaded is None:
    upload_file = st.file_uploader("æœªåœ¨ä»“åº“æ ¹ç›®å½•æ‰¾åˆ°æ¨¡åž‹æ–‡ä»¶ã€‚è¯·ä¸Šä¼ ï¼šbest_model_pipe.pkl æˆ– best_model.pkl", type=["pkl"])
    if upload_file:
        loaded = joblib.load(upload_file)
        loaded_path = Path(upload_file.name)

st.write("ðŸ“„ æ¨¡åž‹æ¥æºï¼š", str(loaded_path) if loaded_path else "ï¼ˆæœªæ‰¾åˆ°ï¼Œä¾èµ–ä¸Šä¼ ï¼‰")
st.write("ðŸ§  å¯¹è±¡ç±»åž‹ï¼š", type(loaded).__name__ if loaded is not None else "None")

if loaded is None or not hasattr(loaded, "predict"):
    st.error("å½“å‰åŠ è½½çš„å¯¹è±¡ä¸æ˜¯å¯é¢„æµ‹çš„æ¨¡åž‹/Pipelineã€‚è¯·ä¸Šä¼ /æ”¾ç½®æ­£ç¡®çš„æ¨¡åž‹æ–‡ä»¶ï¼ˆå»ºè®®ä¸ºåŒ…å«é¢„å¤„ç†çš„ sklearn Pipelineï¼‰ã€‚")
    st.stop()

model = loaded

# ---------- 2) æŽ¨æ–­ç‰¹å¾åï¼šä¼˜å…ˆä½¿ç”¨æ¨¡åž‹çš„ feature_names_in_ï¼›å¦åˆ™å…è®¸æä¾› CSV ----------
st.subheader("â‘¡ å®šä¹‰è¾“å…¥ç‰¹å¾")
feature_names = None
if hasattr(model, "feature_names_in_"):
    feature_names = list(model.feature_names_in_)

csv_df = None
if feature_names is None:
    st.info("æ¨¡åž‹æœªæä¾› feature_names_in_ã€‚è¯·ä¸Šä¼ ä¸€ä¸ªç¤ºä¾‹ CSV ç”¨äºŽæž„å»ºè¡¨å•ã€‚")
    csv_up = st.file_uploader("ä¸Šä¼ ç¤ºä¾‹ CSVï¼ˆåˆ—åå°†ç”¨äºŽç”Ÿæˆè¾“å…¥è¡¨å•ï¼‰", type=["csv"], key="csv_schema")
    if csv_up:
        try:
            csv_df = pd.read_csv(csv_up)
            feature_names = list(csv_df.columns)
        except Exception as e:
            st.error(f"CSV è¯»å–å¤±è´¥ï¼š{e}")

if not feature_names:
    st.error("æ— æ³•ç¡®å®šç‰¹å¾åã€‚è¯·ï¼š1ï¼‰ä½¿ç”¨å¸¦ feature_names_in_ çš„æ¨¡åž‹å¯¼å‡ºï¼›æˆ– 2ï¼‰æä¾›åŒ…å«å®Œæ•´åˆ—åçš„ CSVã€‚")
    st.stop()

# ---------- 3) æž„å»ºè¡¨å•ï¼ˆæ•°å€¼/æžšä¸¾è‡ªåŠ¨åˆ¤æ–­ï¼›ç¡®ä¿æ”¯æŒ thalchï¼‰ ----------
st.subheader("â‘¢ å¡«å†™ç‰¹å¾å€¼")
st.sidebar.header("å¡«å†™ç‰¹å¾")
st.sidebar.caption("æ•°å€¼åˆ—è®¾ç½®åˆ†ä½æ•°èŒƒå›´ï¼›æžšä¸¾åˆ—ç”¨ä¸‹æ‹‰ã€‚")

# è‹¥æœ‰ CSVï¼Œç”¨å®ƒæ¥ä¼°è®¡åˆç†èŒƒå›´/é»˜è®¤å€¼
schema_df = csv_df

def build_default(series: pd.Series):
    if series is None or series.empty:
        return 0 if series is None else (series.median() if pd.api.types.is_numeric_dtype(series) else "")
    if pd.api.types.is_numeric_dtype(series):
        return float(series.median())
    try:
        return series.mode().iloc[0]
    except Exception:
        return ""

def widget_for(col: str):
    series = schema_df[col] if (schema_df is not None and col in schema_df.columns) else None
    is_num = pd.api.types.is_numeric_dtype(series) if series is not None else True
    if is_num:
        if series is not None and not series.empty:
            q01 = float(series.quantile(0.01))
            q99 = float(series.quantile(0.99))
            default = build_default(series)
            non_na = series.dropna()
            is_int_like = len(non_na) > 0 and all(float(x).is_integer() for x in non_na.iloc[: min(200, len(non_na))])
            step = 1.0 if is_int_like else 0.1
        else:
            q01, q99, default, step = 0.0, 100.0, 0.0, 1.0
        return st.sidebar.number_input(col, min_value=q01, max_value=q99, value=float(default), step=step, key=f"num_{col}")
    else:
        opts = series.dropna().unique().tolist() if (series is not None and not series.empty) else []
        if 0 < len(opts) <= 15:
            default = build_default(series) if series is not None else (opts[0] if opts else "")
            idx = opts.index(default) if default in opts else 0
            return st.sidebar.selectbox(col, options=opts or [""], index=idx, key=f"sel_{col}")
        else:
            default = build_default(series) if series is not None else ""
            return st.sidebar.text_input(col, value=str(default), key=f"txt_{col}")

inputs = {c: widget_for(c) for c in feature_names}
X = pd.DataFrame([inputs], columns=feature_names)

st.markdown("**ä½ çš„è¾“å…¥**")
st.dataframe(X, use_container_width=True)

# ---------- 4) é¢„æµ‹ ----------
st.subheader("â‘£ é¢„æµ‹")
if st.sidebar.button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
    try:
        y_pred = model.predict(X)
        st.success(f"é¢„æµ‹ç±»åˆ«ï¼š**{y_pred[0]}**")
        if hasattr(model, "predict_proba"):
            proba = model.predict_proba(X)
            if proba.shape[1] == 2:
                st.info(f"é˜³æ€§æ¦‚çŽ‡ï¼š**{proba[0,1]:.3f}**ï¼›é˜´æ€§æ¦‚çŽ‡ï¼š{proba[0,0]:.3f}")
            else:
                st.write("å„ç±»åˆ«æ¦‚çŽ‡ï¼š")
                st.dataframe(pd.Series(proba[0]).to_frame("probability"))
    except Exception as e:
        st.error(f"é¢„æµ‹å¤±è´¥ï¼š{e}")
        st.caption("å¤šåŠæ˜¯åˆ—å/ç±»åž‹ä¸ä¸€è‡´ã€‚è¯·ç¡®ä¿è¡¨å•åˆ—åä¸Žè®­ç»ƒæ—¶ä¸€è‡´ï¼ˆç»Ÿä¸€ä½¿ç”¨ thalchï¼‰ï¼Œå¹¶ä½¿ç”¨åŒ…å«é¢„å¤„ç†çš„ Pipelineã€‚")

st.divider()
with st.expander("âš™ï¸ ä½¿ç”¨ä¸Žéƒ¨ç½²æç¤º"):
    st.markdown("""
- **æ¨¡åž‹æ–‡ä»¶ä¼˜å…ˆé¡ºåº**ï¼š`best_model_pipe.pkl` â†’ `best_model.pkl` â†’ ä¸Šä¼ ã€‚
- **å¼ºçƒˆå»ºè®®**ï¼šæŠŠé¢„å¤„ç†ä¸Žæ¨¡åž‹ä¸€èµ·å°è£…ä¸º `sklearn.pipeline.Pipeline` å†å¯¼å‡ºã€‚
- **éƒ¨ç½²**ï¼šå°† `app.py`ã€`requirements.txt`ã€æ¨¡åž‹æ–‡ä»¶æ”¾åˆ° GitHub ä»“åº“æ ¹ç›®å½•ï¼ŒStreamlit Community Cloud é€‰æ‹©è¯¥ä»“åº“å³å¯ã€‚
- **åˆ—å**ï¼šè¯·ç»Ÿä¸€ç”¨ `thalch` ä½œä¸ºæœ€å¤§å¿ƒçŽ‡å­—æ®µåï¼ˆä¸æ˜¯ `thalach`ï¼‰ã€‚
""")
